# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VO911TJfndYHkU8x5Qim6e-g6RaE-0b2
"""

import os
import numpy as np
import pandas as pd
import scipy
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt
from skimage import io
# %matplotlib inline
plt.style.use('bmh')

url='https://raw.githubusercontent.com/lohitkhanna/EDA-in-python/master/train.csv'
df=pd.read_csv(url)
df.head()



# Counting No by condition as in Target Variable
Counttarget =df[df["SaleCondition"]=="Normal"].shape
print(" The no of Normal Condition",Counttarget[0])

# Counting by class/Type in different column
Nd =df[df["SaleCondition"]=="Normal"]

# After Sybset making Cross tab
Freq_table = pd.crosstab(index=Nd["SaleCondition"], 
                            columns=Nd["MSZoning"])
print("Crosstab",Freq_table)

df.isnull().sum().sum()

# To check if there is nan
df.isnull().any().any()
#to know how many rows there are with "one or more NaNs"
df.isnull().T.any().T.sum()

# Check which row has nan
nan_rows = df[df.isnull().any(1)]
print(nan_rows)

# Dropping Column having greater > 30% missing value
pct_null = df.isnull().sum() / len(df)
missing_features = pct_null[pct_null > 0.30].index
df.drop(missing_features, axis=1, inplace=True)

# drop row having greater then 2 na
df.dropna(thresh=2)

df.shape

# Filling data by forward or backward - similar to time series

df.isnull().values.any()
# Check null values by column

# Missing value treatment using time series/pad forward
df.fillna(method='pad')

df.shape

# Creating Dependent and independent variable
Y=df.iloc[:,-2]
X=df.iloc[:,:-2]
X1=df.iloc[:,-1]
# Joining last column with X
X=X.join(X1)



# Checking Unique Target

print(set(Y),'\n'' No of classes in Target : ',len(set(Y)))

# Checking types and storing variable
objecttype=df.select_dtypes(include='object').columns
floattype=df.select_dtypes(include='float64').columns
inttype=df.select_dtypes(include='int64').columns
booltype=df.select_dtypes(include='bool').columns

# Dummy data
from sklearn.preprocessing import OneHotEncoder
Y_dummy = pd.get_dummies(Y)
Y_dummy
# We will use now Y dummy as Target Variable

# Distribution of target by class type
Y_dummy.sum()

# Train Test split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y_dummy, test_size=0.3, random_state=42)

# Over Sampling - Need for the same due to class imbalance, so do it train data

# Over sammling usinf packages to remove data imbalnce
# Multi class problem

x_train.shape,y_train.shape

# SMOTE uses KNN technique and works on minority class
from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import RandomOverSampler

sm = SMOTE(random_state=12, ratio = 1.0)
ros = RandomOverSampler(random_state=0)
# Not able to do in df , will try later



